CS 3700 Project 5: Web Crawler

PROJECT DESCIPTION:
The goal in this project is to implement a web crawler that gathers data from a fake social networking website
in order to familiarize us with the HTTP protocol. This project will expose us to the HTTP protocol, 
which underlies a large (and growing) number of applications and services today, let us see how web pages are structured using HTML, 
give us experience implementing a client for a well-specified network protocol, and allow us to 
understand how web crawlers work and how they are used to implement popular web services today.

APPROACH:
The approach that I had while completing this project was to break the pieces down into separate 
components and to effectively get through each individual component before proceeding to the next.
We initially started with seeing what response we would get with a GET request. While debugging the 
errors that we got from that, we started to understand exactly what we needed to do to continue with the 
other requests. 

CHALLENGES:
Some challenges that we faced while completing this project was formatting the HTTP requests,
and optimizing our code so that it doesn't get timed out on the submission page. 

TESTING:
We tested our application through the various stages of each step in our project by using print statements
in order to see the html and the response that we got. Using these debuging outputs, we can accurately figure
out which part of our code needs to be fixed. 